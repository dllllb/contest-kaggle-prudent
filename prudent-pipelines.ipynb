{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://www.kaggle.com/c/prudential-life-insurance-assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.optimize import fmin_powell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ds_tools/dstools/ml/metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ds_tools/dstools/ml/ensemble.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dmitri/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run ds_tools/dstools/ml/xgboost_tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preds_to_rank(preds, min, max):\n",
    "    return np.clip(np.round(preds), min, max).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qwk_score(est, features, labels):\n",
    "    raw_pred = est.predict(features)\n",
    "    pred = preds_to_rank(raw_pred, np.min(labels), np.max(labels))\n",
    "    return quadratic_weighted_kappa(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_offset(pred_base, pred_modified, labels, offset, rank_number, scorer):\n",
    "    pred_modified[pred_base.astype(int) == rank_number] = pred_base[pred_base.astype(int) == rank_number] + offset\n",
    "    rank = preds_to_rank(pred_modified, np.min(labels), np.max(labels))\n",
    "    score = scorer(labels, rank)\n",
    "    return score\n",
    "\n",
    "def apply_offsets(data, offsets):\n",
    "    res = np.copy(data)\n",
    "    for j in range(len(offsets)):\n",
    "        res[data.astype(int) == j] = data[data.astype(int) == j] + offsets[j]\n",
    "    return res\n",
    "\n",
    "def minimize_reminders(preds, true, scorer):\n",
    "    offsets = np.zeros(len(set(true)))\n",
    "    optimized_preds = apply_offsets(preds, offsets)\n",
    "    for j in range(len(offsets)):\n",
    "        def train_offset(x): return -score_offset(preds, optimized_preds, true, x, j, scorer) * 100\n",
    "        offsets[j] = fmin_powell(train_offset, offsets[j])\n",
    "    return offsets\n",
    "\n",
    "class RemindersMinimizingRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, base_estimator, scorer):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.scorer = scorer\n",
    "        self.offsets = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_estimator.fit(X, y)\n",
    "        preds = self.base_estimator.predict(X)\n",
    "\n",
    "        self.offsets = minimize_reminders(preds, y, self.scorer)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = self.base_estimator.predict(X)\n",
    "        preds_fix = apply_offsets(preds, self.offsets)\n",
    "        return preds_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_test(est):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='Id')\n",
    "    features = df.drop(['Response'], axis=1)\n",
    "    target = df['Response'].values\n",
    "    scores = cross_val_score(\n",
    "        estimator=est,\n",
    "        X=features,\n",
    "        y=target,\n",
    "        cv=StratifiedKFold(target, 3, shuffle=True),\n",
    "        scoring=qwk_score,\n",
    "        n_jobs=1,\n",
    "        verbose=1)\n",
    "    print('mean: {mean}, std: {std}'.format(mean=scores.mean(), std=scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submission(est, name='results'):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='Id')\n",
    "    features = df.drop(['Response'], axis=1)\n",
    "    target = df['Response'].values\n",
    "    model = est.fit(features, target)\n",
    "\n",
    "    df_test = pd.read_csv('test.csv.gz', index_col='Id')\n",
    "\n",
    "    y_pred = preds_to_rank(model.predict(df_test), np.min(target), np.max(target))\n",
    "\n",
    "    res = pd.Series(y_pred, index=df_test.index, name='Response')\n",
    "    res.to_csv(name+'.csv', index_label='Id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_vs_true(est, path):\n",
    "    df = pd.read_csv('train.csv.gz', index_col='Id')\n",
    "    features = df.drop(['Response'], axis=1)\n",
    "    target = df['Response'].values\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, train_size=0.9)\n",
    "    y_pred = est.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "    pd.DataFrame({'pred': y_pred, 'true': y_test}).to_csv(path, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results_corr(pred_files):\n",
    "    preds = np.array([pd.read_csv(file, index_col='Id', squeeze=True) for file in pred_files], dtype=np.int32)\n",
    "    print DataFrame(np.corrcoef(preds), index=pred_files, columns=pred_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submission_mix(pred_files, name):\n",
    "    preds = DataFrame(dict([(file, pd.read_csv(file, index_col='Id', squeeze=True)) for file in pred_files]))\n",
    "    mix = preds_to_rank(preds.mean(axis=1), 1, 8)\n",
    "    res = Series(mix, index=preds.index, name='Response')\n",
    "    res.to_csv(name+'.csv', index_label='Id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submission_mix_m(pred_files, name):\n",
    "    preds = DataFrame(dict([(file, pd.read_csv(file, index_col='Id', squeeze=True)) for file in pred_files]))\n",
    "    mix = preds.mode(axis=1)[0]\n",
    "    mix[mix.isnull()] = preds.median(axis=1)\n",
    "    res = Series(mix.astype(int), name='Response')\n",
    "    res.to_csv(name+'.csv', index_label='Id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2dict = FunctionTransformer(\n",
    "    lambda x: x.to_dict(orient='records'), validate=False)\n",
    "\n",
    "transf1 = make_pipeline(\n",
    "    df2dict,\n",
    "    DictVectorizer(sparse=False),\n",
    "    Imputer(strategy='median'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eta\": 0.01,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"silent\": 1,\n",
    "    \"max_depth\": 6,\n",
    "    \"num_rounds\": 10000,\n",
    "    \"num_es_rounds\": 120,\n",
    "    \"es_share\": .05,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.605788631592, std: 0.00317117715894\n",
    "# cv execution time: 334.374572039 sec\n",
    "pl1 = make_pipeline(transf1, XGBoostRegressor(**xgb_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.58282885229129844, std: 0.0036042550445012792\n",
    "# cv execution time: 398.817314148 sec\n",
    "pl3 = make_pipeline(transf1, RandomForestRegressor(n_estimators=200, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.58556649850197451, std: 0.001689581447944851\n",
    "# cv execution time: 437.633708954 sec\n",
    "pl4 = make_pipeline(transf1, ExtraTreesRegressor(n_estimators=200, n_jobs=-1, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.610298252514, std: 0.0051761541879\n",
    "# cv execution time: 344.473729849 sec\n",
    "pl10 = make_pipeline(\n",
    "    transf1,\n",
    "    ModelEnsembleRegressor(\n",
    "        intermediate_estimators=[\n",
    "            XGBoostRegressor(**xgb_params),\n",
    "        ],\n",
    "        assembly_estimator=DecisionTreeClassifier(max_depth=2),\n",
    "        ensemble_train_size=1\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean: 0.654195672603, std: 0.0032825843272\n",
    "# cv execution time: 386.967167854 sec\n",
    "pl19 = make_pipeline(\n",
    "    transf1,\n",
    "    RemindersMinimizingRegressor(\n",
    "        base_estimator=XGBoostRegressor(**xgb_params),\n",
    "        scorer=quadratic_weighted_kappa\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
